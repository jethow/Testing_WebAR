<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Multiâ€‘Face 3D Hat Filter</title>

  <!-- Three.js -->
  <script src="https://unpkg.com/three@0.152.2/build/three.min.js"></script>
  <script src="https://unpkg.com/three@0.152.2/examples/js/loaders/GLTFLoader.js"></script>

  <!-- MediaPipe Face Mesh -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
    video {
      position: absolute;
      width: 100%;
      height: auto;
      top: 0;
      left: 0;
      transform: scaleX(-1);
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      pointer-events: none;
    }
  </style>
</head>

<body>

  <video id="video" autoplay muted playsinline></video>

  <script>
    // ====== THREE.JS SETUP ======
    const scene = new THREE.Scene();
    const camera3D = new THREE.PerspectiveCamera(
      45,
      window.innerWidth / window.innerHeight,
      0.1,
      1000
    );
    camera3D.position.z = 5;
    const renderer = new THREE.WebGLRenderer({ alpha: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.body.appendChild(renderer.domElement);

    // Array to hold hat meshes
    const hats = [];

    // Load GLB hat model
    const loader = new THREE.GLTFLoader();
    loader.load("hat.glb", (gltf) => {
      const baseHat = gltf.scene;

      // Prepare a pool of hats (for up to 5 faces)
      for (let i = 0; i < 5; i++) {
        const hat = baseHat.clone();
        hat.scale.set(1, 1, 1);
        hat.visible = false;
        scene.add(hat);
        hats.push(hat);
      }
    });

    // ====== CAMERA (MEDIA PIPE) ======
    const video = document.getElementById("video");

    const faceMesh = new FaceMesh({
      locateFile: (file) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });

    faceMesh.setOptions({
      maxNumFaces: 5,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults(onResults);

    const cameraMP = new Camera(video, {
      onFrame: async () => {
        await faceMesh.send({ image: video });
      },
      width: 640,
      height: 480
    });
    cameraMP.start();

    function onResults(results) {
      if (!results.multiFaceLandmarks) return;

      // Hide all hats if no faces
      hats.forEach(hat => (hat.visible = false));

      results.multiFaceLandmarks.forEach((landmarks, index) => {
        if (index >= hats.length) return; // skip if too many faces
        const hat = hats[index];
        hat.visible = true;

        const leftEye = landmarks[33];
        const rightEye = landmarks[263];
        const forehead = landmarks[10];

        // Position
        const x = (leftEye.x + rightEye.x) / 2 - 0.5;
        const y = -(forehead.y - 0.5);
        hat.position.set(x * 6, y * 4 + 0.8, 0);

        // Scale based on face width
        const faceWidth = Math.abs(rightEye.x - leftEye.x);
        hat.scale.set(faceWidth * 4, faceWidth * 4, faceWidth * 4);

        // Optionally, rotate hat backwards if needed
      });
    }

    // ====== RENDER LOOP ======
    function animate() {
      requestAnimationFrame(animate);
      renderer.render(scene, camera3D);
    }
    animate();

    window.addEventListener("resize", () => {
      renderer.setSize(window.innerWidth, window.innerHeight);
      camera3D.aspect = window.innerWidth / window.innerHeight;
      camera3D.updateProjectionMatrix();
    });
  </script>
</body>
</html>
